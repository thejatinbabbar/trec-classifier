services:
  mlflow-server:
    build:
      context: .
      dockerfile: mlflow.Dockerfile
    ports:
      - "5001:5001"
    volumes:
      - ./mlruns:/opt
    environment:
      - MLFLOW_TRACKING_URI=http://localhost:5001
    command: mlflow server --host 0.0.0.0 --port 5001 # --backend-store-uri sqlite:///mlflow.db --default-artifact-root /opt/mlruns/artifacts
    

  training:
    build:
      context: .
      dockerfile: train.Dockerfile
    volumes:
      # - ./mlruns:/opt/mlflow/models
      - ./classifier:/app/classifier
      - ./config:/app/config
    environment:
      - PYTHONPATH=${PYTHONPATH}:/app
      - MLFLOW_TRACKING_URI=http://mlflow-server:5001
      - GIT_PYTHON_REFRESH=quiet
      # - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      # - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    depends_on:
      - mlflow-server
    # ports:
    #   - "5002:5002"
    command: poetry run python classifier/main.py --experiment_name trec-classifier --config config/config.yml

  inference:
    build:
      context: .
      dockerfile: inference.Dockerfile
    ports:
      - "5000:5000"    # Expose Flask app
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow-server:5001
      - PYTHONPATH=${PYTHONPATH}:/app
      # - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      # - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    depends_on:
      - mlflow-server
    command: poetry run flask run --host 0.0.0.0 --port 5000
    # command: poetry run curl http://mlflow-server:5001/api/2.0/mlflow/experiments/list
